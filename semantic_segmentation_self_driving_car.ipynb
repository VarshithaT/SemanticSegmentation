{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "semantic-segmentation-self-driving-car.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtvBiYdkgSsH",
        "outputId": "4ea92610-dc78-40fd-a3bd-05065213447f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ht40o0GgPen"
      },
      "source": [
        "# ***Brief Introduction***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD1uPreVgPer"
      },
      "source": [
        "In this notebook, we are trying to do semantic segmentation for self driving cars.\n",
        "\n",
        "The [dataset](https://www.kaggle.com/kumaresanmanickavelu/lyft-udacity-challenge) provides data images and labeled semantic segmentations captured via CARLA self-driving car simulator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjNZenoAgPet"
      },
      "source": [
        "First let's import the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:45.373718Z",
          "iopub.execute_input": "2021-11-08T14:37:45.374078Z",
          "iopub.status.idle": "2021-11-08T14:37:49.003880Z",
          "shell.execute_reply.started": "2021-11-08T14:37:45.374039Z",
          "shell.execute_reply": "2021-11-08T14:37:49.002992Z"
        },
        "trusted": true,
        "id": "WaO_OnN_gPev"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model \n",
        "from tensorflow.keras.layers import Conv2D, concatenate, Activation, MaxPooling2D, UpSampling2D, Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GseMwkUXgPey"
      },
      "source": [
        "# ***Data Preparation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zdpj5g5gPez"
      },
      "source": [
        "Because The data in our dataset is split across five folders, and for other reasons we will do some data preprcessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL9colmej1Lw"
      },
      "source": [
        "#/content/drive/MyDrive/ SemanticSegmentationforSelfDrivingCars\n",
        "path = '/content/drive/MyDrive/ SemanticSegmentationforSelfDrivingCars/'\n",
        "images_path = [path + 'data' + i + '/' + 'data' + i + '/' + 'CameraRGB' for i in ['A', 'B', 'C', 'D']]\n",
        "masks_path = [path + 'data' + i + '/' + 'data' + i + '/' + 'CameraSeg' for i in ['A', 'B', 'C', 'D']]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:49.005713Z",
          "iopub.execute_input": "2021-11-08T14:37:49.006058Z",
          "iopub.status.idle": "2021-11-08T14:37:49.012988Z",
          "shell.execute_reply.started": "2021-11-08T14:37:49.006005Z",
          "shell.execute_reply": "2021-11-08T14:37:49.012141Z"
        },
        "trusted": true,
        "id": "MQDoX5fEgPe0"
      },
      "source": [
        "# Create Lists of images and masks paths\n",
        "#path = '/content/drive/MyDrive/VehicleDataset/ Semantic Segmentation for Self Driving Cars/dataA'\n",
        "#images_path = \"/content/drive/MyDrive/VehicleDataset/dataA/dataA/CameraRGB\"\n",
        "#masks_path = \"/content/drive/MyDrive/VehicleDataset/dataA/dataA/CameraSeg\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mCHEhGpj9l8"
      },
      "source": [
        "def return_paths(path):\n",
        "    X = []\n",
        "    for i in sorted(path):\n",
        "        g = sorted(os.listdir(i))\n",
        "        for j in g:\n",
        "            X.append(i + '/' + j)\n",
        "    return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvcbi27wtpE-"
      },
      "source": [
        "X = return_paths(images_path)\n",
        "Y = return_paths(masks_path)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4bM1qJuuABL",
        "outputId": "e78a6588-c9b7-414b-8ad6-9a5a236df407"
      },
      "source": [
        "!cd /content/drive/MyDrive/ SemanticSegmentationforSelfDrivingCars"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: too many arguments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:49.024563Z",
          "iopub.execute_input": "2021-11-08T14:37:49.025151Z",
          "iopub.status.idle": "2021-11-08T14:37:49.798263Z",
          "shell.execute_reply.started": "2021-11-08T14:37:49.025109Z",
          "shell.execute_reply": "2021-11-08T14:37:49.797461Z"
        },
        "trusted": true,
        "id": "alStkBUVgPe3"
      },
      "source": [
        "# Creating two lists of the images and masks pathes respectively.\n",
        "#X = '/content/drive/MyDrive/ Semantic Segmentation for Self Driving Cars/dataA/dataA/CameraRGB'\n",
        "#Y = '/content/drive/MyDrive/ Semantic Segmentation for Self Driving Cars/dataA/dataA/CameraSeg'\n",
        "\n",
        "#X = os.listdir(os.path.join(images_path))\n",
        "#Y = os.listdir(os.path.join(masks_path))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag86YL34kCac"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNk8UlT3gPe4"
      },
      "source": [
        "# ***Splitting the data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjRk7uWBgPe5"
      },
      "source": [
        "Now that we have two lists containing all the images and masks we have, We are ready to split our data into training, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:49.801765Z",
          "iopub.execute_input": "2021-11-08T14:37:49.802068Z",
          "iopub.status.idle": "2021-11-08T14:37:49.812134Z",
          "shell.execute_reply.started": "2021-11-08T14:37:49.802039Z",
          "shell.execute_reply": "2021-11-08T14:37:49.811105Z"
        },
        "trusted": true,
        "id": "vl6g6lZogPe6"
      },
      "source": [
        "# Splitting the data into train, validation and test sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.1)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size = 0.2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwnDfhi_gPe6"
      },
      "source": [
        "# ***Custom Data Generators***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57AiqjDpgPe7"
      },
      "source": [
        "Now that we have prepared and splitted our data, we need to define our Generators that are responsible for loading batches of the data and feed them to the model.\n",
        "Before this step, we will need to defind a function that will be reponsible for loading, and resizing images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:49.815668Z",
          "iopub.execute_input": "2021-11-08T14:37:49.816092Z",
          "iopub.status.idle": "2021-11-08T14:37:49.824886Z",
          "shell.execute_reply.started": "2021-11-08T14:37:49.816064Z",
          "shell.execute_reply": "2021-11-08T14:37:49.824069Z"
        },
        "trusted": true,
        "id": "kCcIbMTegPe7"
      },
      "source": [
        "# This function will load and resize images and return arrays to the generators\n",
        "def read_imageMask(image_path, mask_path):\n",
        "    \n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, (256, 256), method='nearest')\n",
        "    \n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n",
        "    mask = tf.image.resize(mask, (256, 256), method='nearest')\n",
        "    \n",
        "    return img, mask"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:49.826348Z",
          "iopub.execute_input": "2021-11-08T14:37:49.826768Z",
          "iopub.status.idle": "2021-11-08T14:37:49.837307Z",
          "shell.execute_reply.started": "2021-11-08T14:37:49.826731Z",
          "shell.execute_reply": "2021-11-08T14:37:49.836432Z"
        },
        "trusted": true,
        "id": "dLCmxNZKgPe8"
      },
      "source": [
        "# Defining our custom generator\n",
        "def data_generator(image_paths, mask_paths, batch_size):\n",
        "    images = tf.constant(image_paths)\n",
        "    masks = tf.constant(mask_paths)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, masks))\n",
        "    dataset = dataset.map(read_imageMask, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.cache().shuffle(500).batch(batch_size)\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:49.838501Z",
          "iopub.execute_input": "2021-11-08T14:37:49.840166Z",
          "iopub.status.idle": "2021-11-08T14:37:50.757707Z",
          "shell.execute_reply.started": "2021-11-08T14:37:49.840123Z",
          "shell.execute_reply": "2021-11-08T14:37:50.756852Z"
        },
        "trusted": true,
        "id": "0UyYjGVrgPe9"
      },
      "source": [
        "# Now we are ready to create the train, validation and test generators\n",
        "train_generator = data_generator(X_train, Y_train, 32)\n",
        "val_generator = data_generator(X_val, Y_val, 32)\n",
        "test_generator = data_generator(X_test, Y_test, 32)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xfwNi7EgPe-"
      },
      "source": [
        "# ***Model***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcsLD-q8gPe-"
      },
      "source": [
        "Now that we have reached this point, Let's define our model.\n",
        "\n",
        "For this Task We will use the U-net architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:50.759306Z",
          "iopub.execute_input": "2021-11-08T14:37:50.759733Z",
          "iopub.status.idle": "2021-11-08T14:37:50.788381Z",
          "shell.execute_reply.started": "2021-11-08T14:37:50.759686Z",
          "shell.execute_reply": "2021-11-08T14:37:50.787194Z"
        },
        "trusted": true,
        "id": "7Zp6PwH_gPe_"
      },
      "source": [
        "def unet(num_classes = 13, image_shape = (256, 256, 3)):\n",
        "    # Input\n",
        "    inputs = Input(image_shape)\n",
        "    # Encoder Path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D((2,2))(conv1)\n",
        "    \n",
        "    conv2 = Conv2D(128, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D((2,2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D((2,2))(conv3)\n",
        "    \n",
        "    conv4 = Conv2D(512, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D((2,2))(drop4)\n",
        "    \n",
        "    conv5 = Conv2D(1024, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', kernel_initializer = 'he_normal', padding='same')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "    \n",
        "    # Decoder Path\n",
        "    up6 = Conv2D(512, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(drop5))\n",
        "    merge6 = concatenate([up6, conv4], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
        "    \n",
        "    up7 = Conv2D(256, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(conv6))\n",
        "    merge7 = concatenate([up7, conv3], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
        "    \n",
        "    up8 = Conv2D(128, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(conv7))\n",
        "    merge8 = concatenate([up8, conv2], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n",
        "    \n",
        "    up9 = Conv2D(64, 2, activation='relu', kernel_initializer='he_normal', padding='same')(UpSampling2D(size=(2,2))(conv8))\n",
        "    merge9 = concatenate([up9, conv1], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n",
        "    \n",
        "    conv10 = Conv2D(num_classes, (1, 1), padding='same', activation='softmax')(conv9)\n",
        "    \n",
        "    model = Model(inputs, conv10)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:50.789970Z",
          "iopub.execute_input": "2021-11-08T14:37:50.790506Z",
          "iopub.status.idle": "2021-11-08T14:37:51.404889Z",
          "shell.execute_reply.started": "2021-11-08T14:37:50.790469Z",
          "shell.execute_reply": "2021-11-08T14:37:51.404014Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORbkMS-NgPe_",
        "outputId": "ad2befec-236c-4fa5-d295-62efbec772cf"
      },
      "source": [
        "# Create The Model\n",
        "model = unet()\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 32, 32, 512)  0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['conv2d_8[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16, 16, 1024  0           ['conv2d_9[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 32, 32, 1024  0           ['dropout_1[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 512)  2097664     ['up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_10[0][0]',              \n",
            "                                )                                 'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 256)  524544      ['up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_13[0][0]',              \n",
            "                                                                  'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_15[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 128, 128, 12  131200      ['up_sampling2d_2[0][0]']        \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_16[0][0]',              \n",
            "                                6)                                'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_17[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_18[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 256, 256, 64  32832       ['up_sampling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_19[0][0]',              \n",
            "                                8)                                'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_20[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 256, 256, 13  845         ['conv2d_21[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,032,525\n",
            "Trainable params: 31,032,525\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxbYq5HGgPfB"
      },
      "source": [
        "# ***Compling and Training***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:51.409548Z",
          "iopub.execute_input": "2021-11-08T14:37:51.409806Z",
          "iopub.status.idle": "2021-11-08T14:37:51.430160Z",
          "shell.execute_reply.started": "2021-11-08T14:37:51.409779Z",
          "shell.execute_reply": "2021-11-08T14:37:51.429317Z"
        },
        "trusted": true,
        "id": "UAVRbaMXgPfB"
      },
      "source": [
        "# Complile The Model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the Callbacks we will use during training\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience= 20)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=1e-1, patience=5, verbose=1, min_lr = 2e-6)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T14:37:51.434266Z",
          "iopub.execute_input": "2021-11-08T14:37:51.434552Z",
          "iopub.status.idle": "2021-11-08T15:36:36.804080Z",
          "shell.execute_reply.started": "2021-11-08T14:37:51.434526Z",
          "shell.execute_reply": "2021-11-08T15:36:36.803152Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XciYPhbgPfC",
        "outputId": "c345e15b-79b7-403e-cffd-a58c769f06b0"
      },
      "source": [
        "# Train the Model\n",
        "history = model.fit(train_generator, validation_data=val_generator,epochs=25,\n",
        "                    verbose = 1, batch_size=16,\n",
        "                    callbacks=[earlystopping, reduce_lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "  4/113 [>.............................] - ETA: 6:56:00 - loss: 500.0469 - accuracy: 0.1914"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvE-IuVwgPfC"
      },
      "source": [
        "# ***Evaluation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pga3ka6agPfD"
      },
      "source": [
        "Let's Now Visualize the Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T15:36:36.807428Z",
          "iopub.execute_input": "2021-11-08T15:36:36.807737Z",
          "iopub.status.idle": "2021-11-08T15:36:37.145087Z",
          "shell.execute_reply.started": "2021-11-08T15:36:36.807705Z",
          "shell.execute_reply": "2021-11-08T15:36:37.144229Z"
        },
        "trusted": true,
        "id": "IL3trauGgPfD"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMyqjY4FgPfD"
      },
      "source": [
        "Evaluate The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T15:36:37.146503Z",
          "iopub.execute_input": "2021-11-08T15:36:37.146995Z",
          "iopub.status.idle": "2021-11-08T15:37:36.724747Z",
          "shell.execute_reply.started": "2021-11-08T15:36:37.146955Z",
          "shell.execute_reply": "2021-11-08T15:37:36.724032Z"
        },
        "trusted": true,
        "id": "iTPL8Hj-gPfE"
      },
      "source": [
        "train_loss, train_accuracy = model.evaluate(train_generator, batch_size = 32)\n",
        "validation_loss, validation_accuracy = model.evaluate(val_generator, batch_size = 32)\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kKCGnCIgPfE"
      },
      "source": [
        "Visualize The results of our Model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-08T15:37:36.727714Z",
          "iopub.execute_input": "2021-11-08T15:37:36.728055Z",
          "iopub.status.idle": "2021-11-08T15:37:43.224860Z",
          "shell.execute_reply.started": "2021-11-08T15:37:36.727998Z",
          "shell.execute_reply": "2021-11-08T15:37:43.224011Z"
        },
        "trusted": true,
        "id": "FSzfuvisgPfE"
      },
      "source": [
        "for image, mask in test_generator.take(6):\n",
        "    pred_mask = model.predict(image)\n",
        "    \n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(image[0]))\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(mask[0]))\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(tf.expand_dims(tf.argmax(pred_mask[0], axis = -1), axis = -1)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}